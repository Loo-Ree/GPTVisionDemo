{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1702986269697
        }
      },
      "outputs": [],
      "source": [
        "# ! pip install trulens_eval\n",
        "# #! pip install chromadb\n",
        "# ! pip install openai\n",
        "# ! pip install llama_index\n",
        "! pip install trulens_eval==0.19.2 openai==1.3.7 llama_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1702986273881
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "#!!! TODO: inserire i parametri di accesso e di configurazione del dataset di evaluation !!!\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "API_KEY = \"51166339f2f3498eb48e07a1c57a24b9\"\n",
        "\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2023-07-01-preview\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = API_KEY\n",
        "os.environ[\"AZURE_OPENAI_API_BASE\"] = \"https://oaimfuccilo.openai.azure.com/\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://oaimfuccilo.openai.azure.com/openai/deployments/gpt-35-turbo-16k/chat/completions?api-version=2023-07-01-preview\"\n",
        "\n",
        "deployment_name = \"gpt-35-turbo-16k\"\n",
        "TestName = \"MioTest\"\n",
        "cleanDB = True\n",
        "\n",
        "#il dataset delle registrazioni dei test, in formato csv, che contenga le colonne: domanda, risposta, contesto\n",
        "dataset_url = \"test_dataset.csv\"\n",
        "dataset_delim = \";\"\n",
        "#se il dataset contiene l'header\n",
        "dataset_header = True\n",
        "#la posizione delle colonne nel dataset\n",
        "dataset_column_question = 1\n",
        "dataset_column_context = 3\n",
        "dataset_column_response = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1702986289392
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from trulens_eval import Tru\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "tru = Tru()\n",
        "#tru = Tru(database_url=\"sqlite:///mydb.sqlite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cleanDB:\n",
        "    tru.reset_database()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "#il dataset delle registrazioni dei test\n",
        "DBEval = list()\n",
        "\n",
        "with open(dataset_url) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=dataset_delim)\n",
        "    DBEval = list(csv_reader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1702984937700
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#il wrapper all'applicazione RAG\n",
        "class RAG_app_facade:\n",
        "    @instrument\n",
        "    def retrieve(self, query: str, **kwargs) -> list:\n",
        "        \"\"\"\n",
        "        Retrieve relevant text from index store.\n",
        "        \"\"\"\n",
        "        row = kwargs.get('eval_row', 1)\n",
        "        result = DBEval[row][dataset_column_context]\n",
        "        \n",
        "        return result\n",
        "\n",
        "    @instrument\n",
        "    def generate_completion(self, query: str, context_str: list, **kwargs) -> str:\n",
        "        \"\"\"\n",
        "        Generate answer from context.\n",
        "        \"\"\"\n",
        "        row = kwargs.get('eval_row', 1)\n",
        "        completion = DBEval[row][dataset_column_response]\n",
        "        return completion\n",
        "\n",
        "    @instrument\n",
        "    def query(self, query: str, **kwargs) -> str:\n",
        "        row = kwargs.get('eval_row', 1)\n",
        "        context_str = self.retrieve(query, eval_row=row)\n",
        "        completion = self.generate_completion(query, context_str, eval_row=row)\n",
        "        return completion\n",
        "\n",
        "rag = RAG_app_facade()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1702984945300
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#Le funzioni di feedback da usare per valutare le risposte: https://www.trulens.org/trulens_eval/function_definitions/\n",
        "from trulens_eval import Feedback, Select\n",
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval.feedback.provider.openai import AzureOpenAI as fOpenAI\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Initialize provider class\n",
        "fopenai = fOpenAI(deployment_name=deployment_name, api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"))\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=fopenai)\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = (\n",
        "    Feedback(fopenai.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(fopenai.qs_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1702984958637
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "tru_rag = TruCustomApp(rag,\n",
        "    app_id = TestName,\n",
        "    feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1702984363543
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#Avvio la registrazione dell'app utilizzando il dataset registrato\n",
        "with tru_rag as recording:\n",
        "    for i in range(DBEval.__len__()):\n",
        "        if i == 0 & dataset_header:\n",
        "            continue\n",
        "        else:\n",
        "            test = DBEval[i]\n",
        "            ask = test[dataset_column_question]\n",
        "            response = rag.query(ask, eval_row=i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1702984363572
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "tru.get_leaderboard(app_ids=[TestName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1702984363598
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "tru.run_dashboard()\n",
        "#http://127.0.0.1:8501/"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
