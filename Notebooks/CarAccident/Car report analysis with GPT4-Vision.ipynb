{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a732a0",
   "metadata": {},
   "source": [
    "# Car report analysis with GPT4-Vision & Azure AI enhancements\n",
    "\n",
    "GPT-4 Turbo with Vision provides **exclusive access to Azure AI Services tailored enhancements**. When combined with Azure AI Vision, it enhances your chat experience by providing the chat model with more detailed information about visible text in the image and the locations of objects.\n",
    "\n",
    "- The **Optical Character Recognition (OCR) integration** allows the model to produce higher quality responses for dense text, transformed images, and number-heavy financial documents. It also covers a wider range of languages.\n",
    "\n",
    "- The **object grounding integration** brings a new layer to data analysis and user interaction, as the feature can visually distinguish and highlight important elements in the images it processes.\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/gpt-v-quickstart?tabs=enhanced&pivots=rest-api\n",
    "\n",
    "<img src=\"screenshot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21515f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import glob\n",
    "import gradio as gr\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d749917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_openai_version():\n",
    "    \"\"\"\n",
    "    Check Azure Open AI version\n",
    "    \"\"\"\n",
    "    installed_version = openai.__version__\n",
    "\n",
    "    try:\n",
    "        version_number = float(installed_version[:3])\n",
    "    except ValueError:\n",
    "        print(\"Invalid OpenAI version format\")\n",
    "        return\n",
    "\n",
    "    print(f\"Installed OpenAI version: {installed_version}\")\n",
    "\n",
    "    if version_number < 1.0:\n",
    "        print(\"[Warning] You should upgrade OpenAI to have version >= 1.0.0\")\n",
    "        print(\"To upgrade, run: %pip install openai --upgrade\")\n",
    "    else:\n",
    "        print(f\"[OK] OpenAI version {installed_version} is >= 1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_openai_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3197e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80eb9d4",
   "metadata": {},
   "source": [
    "## Azure AI services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c436511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"OpenAI version: {openai.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82109aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Open AI\n",
    "openai.api_type: str = \"azure\"\n",
    "openai.api_key = \"4ac018829faa4e2dac1142aaddb52425\"\n",
    "openai.api_base = \"https://aoimfuccilosw.openai.azure.com\"\n",
    "\n",
    "# Azure AI Vision (aka Azure Computer Vision)\n",
    "azure_aivision_endpoint = \"https://aoivisionmfuccilo.cognitiveservices.azure.com/\"\n",
    "azure_aivision_key = \"f3bcebd78a2c43d5bfa5b2c43cad5f37\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexname = \"car-reports-tests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"GPT4V\"  # This is the deployed name of your GPT4 Vision model from the Azure Open AI studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443f4f5",
   "metadata": {},
   "source": [
    "## Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e195d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 vscode vscode 2.3M Dec 20 13:18 car_report.jpg\n"
     ]
    }
   ],
   "source": [
    "image_file = \"car_report.jpg\"\n",
    "\n",
    "!ls $image_file -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(image_file)\n",
    "img.resize((640, 640))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1c291",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a02cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPT4V_with_AzureAIVision(image_file, prompt):\n",
    "    \"\"\"\n",
    "    GPT-4 Turbo with vision and Azure AI enhancements\n",
    "    \"\"\"\n",
    "    # Testing if image file exists\n",
    "    if not os.path.exists(image_file):\n",
    "        print(f\"[Error] Image file {image_file} does not exist.\")\n",
    "\n",
    "    # Endpoint\n",
    "    base_url = f\"{openai.api_base}/openai/deployments/{model}\"\n",
    "    gpt4vision_endpoint = (\n",
    "        f\"{base_url}/extensions/chat/completions?api-version=2023-12-01-preview\"\n",
    "    )\n",
    "\n",
    "    # Header\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai.api_key}\n",
    "\n",
    "    # Encoded image\n",
    "    base_64_encoded_image = base64.b64encode(open(image_file, \"rb\").read()).decode(\n",
    "        \"ascii\"\n",
    "    )\n",
    "\n",
    "    # Context\n",
    "    context = \"\"\"\n",
    "You are an insurance AI expert. You will analyse a car report document. \n",
    "Always reply in English.\n",
    "\"\"\"\n",
    "\n",
    "    # Payload\n",
    "    json_data = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"enhancements\": {\"ocr\": {\"enabled\": True}, \"grounding\": {\"enabled\": True}},\n",
    "        \"dataSources\": [\n",
    "            {\n",
    "                \"type\": \"AzureComputerVision\",\n",
    "                \"endpoint\": azure_aivision_endpoint,\n",
    "                \"key\": azure_aivision_key,\n",
    "                \"indexName\": indexname,\n",
    "            }\n",
    "        ],\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": context},\n",
    "            {\"role\": \"user\", \"content\": [prompt, {\"image\": base_64_encoded_image}]},\n",
    "        ],\n",
    "        \"max_tokens\": 4000,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 1,\n",
    "    }\n",
    "\n",
    "    # Response\n",
    "    response = requests.post(\n",
    "        gpt4vision_endpoint, headers=headers, data=json.dumps(json_data)\n",
    "    )\n",
    "\n",
    "    # Testing the status code from the model response\n",
    "    if response.status_code == 200:\n",
    "        now = str(datetime.datetime.today().strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "        print(f\"Analysis of image: {image_file}\")\n",
    "        results = json.loads(response.text)\n",
    "        print(\"\\033[1;31;34m\")\n",
    "        print(results[\"choices\"][0][\"message\"][\"content\"])\n",
    "        \n",
    "        prompt_tokens = results[\"usage\"][\"prompt_tokens\"]\n",
    "        completion_tokens = results[\"usage\"][\"completion_tokens\"]\n",
    "        total_tokens = results[\"usage\"][\"total_tokens\"]\n",
    "\n",
    "        print(\"\\n\\033[1;31;32mDone:\", now)\n",
    "        print(f\"Prompt tokens = {prompt_tokens} | Completion tokens = {completion_tokens} \\\n",
    "| Total tokens = {total_tokens}\")\n",
    "        print(\"\\n[Note] These results are generated by an AI\")\n",
    "        print(\"\\033[0m\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    elif response.status_code == 429:\n",
    "        print(\n",
    "            \"[429 Error] Too many requests. Please wait a couple of seconds and try again.\\n\"\n",
    "        )\n",
    "        print(json.loads(response.text))\n",
    "\n",
    "    else:\n",
    "        print(f\"[Error] Error code: {response.status_code}\\n\")\n",
    "        print(json.loads(response.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be34dd",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Classify this document into 'Driver licence', 'Passport', 'European Accident form', 'Others'\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a4907",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the language used in this document?\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Generate a summary\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are the names, cars models of vehicles A and B?\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Display some informations about the brand and model of the vehicle A\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are the damages for vehicles A and B?\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2de3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Do we have injured people?\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f98f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Do we have some witness?\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff96fe",
   "metadata": {},
   "source": [
    "### Let's analyse the drawings from the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46918d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are the main colors of this document?\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Do we have some handwritten text?\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec2a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain the drawings from section number 10 for vehicles A and B\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain the drawing from section number 13\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are the comments in section 14 for vehicles A and B?\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137067fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How many signatures do we have at the end of the document?\"\n",
    "\n",
    "GPT4V_with_AzureAIVision(image_file, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e352830",
   "metadata": {},
   "source": [
    "## Gradio webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_report_webapp_fn(pil_image):\n",
    "    \"\"\"\n",
    "    Function for the Gradio webapp\n",
    "    Input: pil image (pil format)\n",
    "    output: results (string)\n",
    "    \"\"\"\n",
    "    # Endpoint\n",
    "    base_url = f\"{openai.api_base}/openai/deployments/{model}\"\n",
    "    gpt4vision_endpoint = (\n",
    "        f\"{base_url}/extensions/chat/completions?api-version=2023-12-01-preview\"\n",
    "    )\n",
    "\n",
    "    # Header\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai.api_key}\n",
    "\n",
    "    # Encoded image\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    base_64_encoded_image = base64.b64encode(buffered.getvalue()).decode(\"ascii\")\n",
    "\n",
    "    # Context\n",
    "    context = \"\"\"You are an insurance AI expert. You will analyse a car report document. \\\n",
    "Always reply in Italian.\n",
    "\"\"\"\n",
    "    # Full prompt\n",
    "    prompt = \"\"\"\n",
    "You respond with your analysis of the following fields:\n",
    "\n",
    "1. Summary: Create a summary of this car report.\n",
    "2. Names: What are the names of owners of vehicle A and B? \\\n",
    "Just answer like vehicle A = 'SMITH', Vehicle B = 'JOHNSON'\n",
    "3. Vehicles: What is the brand and model of vehicle A and B? \\\n",
    "Just answer like vehicle A = 'AUDI', Vehicle B = 'MERCEDES'\n",
    "4. Date and time: What is the date and time of the accident? \\\n",
    "Just answer like '01-jan-2023 22:00'\n",
    "5. Address: What is the address of the accident? \\\n",
    "Just answer like '78 Avenue de Paris 75012 Paris'\n",
    "6. Damage: Share some information about the damage.\n",
    "Others damage: Display some information about material damage other than to vehicles A and B.\n",
    "7. Injured people: Do we have injured people?\n",
    "8. Section 14 comments: What are the comments in section 14?\n",
    "9. Damage classification: Classify this damage as LIGHT DAMAGE, MEDIUM DAMAGE, SEVERE DAMAGE.\n",
    "10. Drawings #10: Explain the drawings from section number 10 for vehicles A and B?\n",
    "11. Drawing #13: Explain the drawing from section number 13?\n",
    "12. Signatures: Do we have two signatures at the end of this document? \\\n",
    "Just answer like \"Two signatures detected\", \"One signature detected\", \"No signature detected\"\n",
    "\"\"\"\n",
    "    # Payload\n",
    "    json_data = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"enhancements\": {\"ocr\": {\"enabled\": True}, \"grounding\": {\"enabled\": True}},\n",
    "        \"dataSources\": [\n",
    "            {\n",
    "                \"type\": \"AzureComputerVision\",\n",
    "                \"endpoint\": azure_aivision_endpoint,\n",
    "                \"key\": azure_aivision_key,\n",
    "                \"indexName\": indexname,\n",
    "            }\n",
    "        ],\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": context},\n",
    "            {\"role\": \"user\", \"content\": [prompt, {\"image\": base_64_encoded_image}]},\n",
    "        ],\n",
    "        \"max_tokens\": 4000,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 1,\n",
    "    }\n",
    "\n",
    "    # Results\n",
    "    response = requests.post(\n",
    "        gpt4vision_endpoint, headers=headers, data=json.dumps(json_data)\n",
    "    )\n",
    "\n",
    "    # Testing status code\n",
    "    if response.status_code == 200:\n",
    "        results = json.loads(response.text)\n",
    "        print(results)\n",
    "        \n",
    "        res = results[\"choices\"][0][\"message\"][\"content\"]\n",
    "        summary = res.split(\"2. Names:\")[0].replace(\"\\n\", \"\")\n",
    "        sub1 = \"2. Names:\"\n",
    "        res2 = sub1 + res.split(sub1)[1]\n",
    "        sub2 = \"10. Drawings #10:\"\n",
    "        insights = res2.split(sub2)[0]\n",
    "        drawings = sub2 + res2.split(sub2)[1]\n",
    "        return summary, insights, drawings\n",
    "\n",
    "    elif response.status_code == 429:\n",
    "        print(\n",
    "            \"[429 Error] Too many requests. Please wait a couple of seconds and try again.\"\n",
    "        )\n",
    "        print(json.loads(response.text))\n",
    "\n",
    "    else:\n",
    "        print(\"[Error] Error code:\", response.status_code)\n",
    "        print(json.loads(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcde89",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://cdn4.iconfinder.com/data/icons/lined-car-accident/48/a-03-1024.png\"\n",
    "logo = \"<center> <img src= {} width=70px></center>\".format(image_url)\n",
    "title = \"Your car report Copilot - Azure Open AI GPT4 Turbo Vision with Azure AI enhancements\"\n",
    "\n",
    "inputs = gr.Image(type=\"pil\", label=\"Your car report document\") #.style(height=640)\n",
    "outputs = [\n",
    "    gr.Text(label=\"Car report summary\"),\n",
    "    gr.Text(label=\"Car report insights\"),\n",
    "    gr.Text(label=\"Car report drawings analysis\")\n",
    "]\n",
    "\n",
    "example = glob.glob(\"car_report.jpg\")\n",
    "theme = \"gradio/soft\"  # https://huggingface.co/spaces/gradio/theme-gallery\n",
    "\n",
    "car_report_webapp = gr.Interface(\n",
    "    fn=car_report_webapp_fn,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    description=logo,\n",
    "    title=title,\n",
    "    examples=example,\n",
    "    theme=theme,\n",
    ")\n",
    "\n",
    "car_report_webapp.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d676e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
